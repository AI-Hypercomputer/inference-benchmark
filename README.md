# Inference Benchmark

A model server agnostic inference benchmarking tool that can be used to
benchmark LLMs running on differet infrastructure like GPU and TPU. It can also
be ran on a GKE cluster.

